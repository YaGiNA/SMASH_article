\section{考察}
\subsection{コメント生成}
コメント生成の傾向から、提案モデルは入力されたニュース記事が扱うトピックの学習に成功したように見える。
生成されたコメントの多くが政治的内容を含むものが多かった理由として、データセットが扱う内容の影響を受けたことが考えられる。

生成コメントの中で興味深い単語は``breaking:''である。
この単語はフェイクニュースに寄せられたコメントとして生成されていた。
本研究と同じくコメントとして尤もらしい単語を生成するTCNN-URG\cite{ijcai2018-533}でも、
フェイクを示すシグナルとして``!''や``?''、そして``false''が報告されていたが、``breaking:''は報告されていなかった。
よって、この``breaking:''もフェイクニュースを示す重要なシグナルである可能性がある。

生成されたコメントは軒並み文法面に改善点が残されているが、これはデータセットの規模不足が原因として考えられる。
Groverモデルは120GBにも及ぶニュースデータセットから訓練されていた\cite{NIPS2019_9106}ことも考慮すると、
改善のためにはさらなる追加データを収集する必要がある可能性が示されている。

\subsection{真偽分類}
表\ref{tbl:classify_results}を見るに、提案モデルは再現率は優秀だったが適合率に大きな課題を残した。
これは提案モデルがソーシャルコンテキストが制限されている状況でも、制限されたまま真偽分類を行うより多くのフェイクニュースの検出ができることを意味する。

この傾向はファクトチェックが必要なニュースを探す際に役立つことを示唆している。
ただし適合率が低いため他のモデルより多く正しいニュースをフェイクニュースとして誤って検出するため、改善が求められている。
今後は、より多くのデータセットを用いた場合に傾向が変化するか調べる必要があるとみられる。
